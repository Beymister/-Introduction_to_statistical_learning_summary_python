{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Topics covered in this chapter of the book-\n",
    "\n",
    "* 3.1 SimpleLinearRegression ................... 61\n",
    "  * 3.1.1 EstimatingtheCoefficients .............. 61\n",
    "  * 3.1.2 Assessing the Accuracy of the Coefficient Estimates........................ 63\n",
    "  * 3.1.3 AssessingtheAccuracyoftheModel . . . . . . . . . 68\n",
    "* 3.2 MultipleLinearRegression .................. 71\n",
    "  * 3.2.1 Estimating the Regression Coefficients . . . . . . . . 72 3.2.2 SomeImportantQuestions .............. 75\n",
    "* 3.3 Other Considerations in the Regression Model . . . . . . . . 82\n",
    "  * 3.3.1 QualitativePredictors ................. 82\n",
    "  * 3.3.2 ExtensionsoftheLinearModel . . . . . . . . . . . . 86\n",
    "  * 3.3.3 PotentialProblems................... 92\n",
    "* 3.4 TheMarketingPlan ...................... 102\n",
    "* 3.5 Comparison of Linear Regression with K -Nearest Neighbors............................ 104\n",
    "\n",
    "**Following is the summary of concepts along with data and python code-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression** is a approach for predicting a quantitative response Y on the basis of some predictor variables, Xs, assumig a linear relationship between Xs and Y. Mathematically, we can write this linear relationship as\n",
    "\n",
    "Y ≈ β0 + β1X1 + β2X2 ... βnxn \n",
    "\n",
    "β0, β1,.. βn are known as the model coefficients or parameters.\n",
    "\n",
    "The ordinary least squares (OLS) approach chooses β0, β1,.. βn to minimize the RSS (residual sum of squares)- the gap between actual Y and predicted Y.\n",
    "\n",
    "Some important questions of linear regression-\n",
    "\n",
    "* *How good is the relationship between the response and predictors?*\n",
    "F-statistic helps us understand which mathematically equates to ((TSS − RSS)/p)/(RSS/(n−p−1)). \n",
    "\n",
    "* *Deciding on important variables, also known as variable selection.*\n",
    "The p-value of the variable is a good indicator but not the only one. Sometimes, if p is large we are likely to make some false discoveries. There are three classical approaches for this task- \n",
    "  * **Forward selection**- Start from null model and keep adding variables to find the lowest RSS.\n",
    "  * **Backward selection**- Start with all variables, and keep removing the variables with larger p-value till to find lowest RSS or get low individual p-value.\n",
    "  * **Mixed selection**- Mix of two. Start with null model, keep adding till p-value of variables gets larger and then remove that variable. Continue to perform these forward and backward steps until all variables in the model have a sufficiently low p-value, and all variables outside the model would have a large p-value if added to the model. \n",
    "\n",
    "* *Model fit.*\n",
    "Two of the most common numerical measures of model fit are the RSE and R2, the fraction of variance explained. R2 value close to 1 indicates that the model explains a large portion of the variance in the response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.551\n",
      "Model:                            OLS   Adj. R-squared:                  0.549\n",
      "Method:                 Least Squares   F-statistic:                     309.0\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):           2.98e-88\n",
      "Time:                        03:00:12   Log-Likelihood:                -1637.5\n",
      "No. Observations:                 506   AIC:                             3281.\n",
      "Df Residuals:                     503   BIC:                             3294.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     33.2228      0.731     45.458      0.000      31.787      34.659\n",
      "lstat         -1.0321      0.048    -21.416      0.000      -1.127      -0.937\n",
      "age            0.0345      0.012      2.826      0.005       0.011       0.059\n",
      "==============================================================================\n",
      "Omnibus:                      124.288   Durbin-Watson:                   0.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              244.026\n",
      "Skew:                           1.362   Prob(JB):                     1.02e-53\n",
      "Kurtosis:                       5.038   Cond. No.                         201.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Boston = pd.read_csv('/Users/shilpa/Documents/blog/Sharing_ISL_python/data/Boston.csv', header=0)\n",
    "Boston.shape\n",
    "lm = smf.ols('medv~lstat+age', data=Boston).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>medv</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:00:16</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crim</th>      <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zn</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indus</th>     <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chas</th>      <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rm</th>        <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tax</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   medv   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Sun, 11 Oct 2020   Prob (F-statistic):          6.72e-135\n",
       "Time:                        03:00:16   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "crim          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "zn             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "indus          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "chas           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "nox          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "rm             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "age            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "dis           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "rad            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "tax           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "ptratio       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "black          0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "lstat         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"medv~\" + \"+\".join(Boston.columns.drop([\"medv\"]))\n",
    "lm = smf.ols(formula, data=Boston).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Transformations of the Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.641\n",
      "Model:                            OLS   Adj. R-squared:                  0.639\n",
      "Method:                 Least Squares   F-statistic:                     448.5\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):          1.56e-112\n",
      "Time:                        03:01:05   Log-Likelihood:                -1581.3\n",
      "No. Observations:                 506   AIC:                             3169.\n",
      "Df Residuals:                     503   BIC:                             3181.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          42.8620      0.872     49.149      0.000      41.149      44.575\n",
      "lstat              -2.3328      0.124    -18.843      0.000      -2.576      -2.090\n",
      "I(lstat ** 2.0)     0.0435      0.004     11.628      0.000       0.036       0.051\n",
      "==============================================================================\n",
      "Omnibus:                      107.006   Durbin-Watson:                   0.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.388\n",
      "Skew:                           1.128   Prob(JB):                     2.55e-50\n",
      "Kurtosis:                       5.397   Cond. No.                     1.13e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "lm_order1 = smf.ols('medv~ lstat', data=Boston).fit()\n",
    "lm_order2 = smf.ols('medv~ lstat+ I(lstat ** 2.0)', data=Boston).fit()\n",
    "print(lm_order2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   df_resid           ssr  df_diff     ss_diff           F        Pr(>F)\n",
      "0     504.0  19472.381418      0.0         NaN         NaN           NaN\n",
      "1     503.0  15347.243158      1.0  4125.13826  135.199822  7.630116e-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shilpa/Library/Python/3.7/lib/python/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/Users/shilpa/Library/Python/3.7/lib/python/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/Users/shilpa/Library/Python/3.7/lib/python/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "table = sm.stats.anova_lm(lm_order1, lm_order2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stats.anova_lm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
